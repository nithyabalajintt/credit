{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac559b9",
   "metadata": {
    "id": "fac559b9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd30494d",
   "metadata": {
    "id": "fd30494d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'marketing_campaign.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarketing_campaign.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'marketing_campaign.xlsx'"
     ]
    }
   ],
   "source": [
    "df= pd.read_excel(\"marketing_campaign.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97da31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "7d97da31",
    "outputId": "0bedef89-16f2-4da0-951e-2d4569b7ae15"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16df115",
   "metadata": {
    "id": "d16df115"
   },
   "source": [
    "## Basic Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af9a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "a29af9a1",
    "outputId": "420c1636-4145-430f-f5ee-d960f72358d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f91776",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1f91776",
    "outputId": "dfd1b233-c0e1-47eb-8e92-8108a25bb9b4"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca8ac7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90ca8ac7",
    "outputId": "a2ae8c78-694b-4360-9a10-297189b6e504"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffb77148",
   "metadata": {
    "id": "ffb77148"
   },
   "source": [
    "# Income column having missing values.\n",
    "# As no of missing values is less (<5%) , we can remove the rows containing missin values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cbe63",
   "metadata": {
    "id": "7f3cbe63"
   },
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee3760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cee3760",
    "outputId": "713e39fe-2b4a-4b60-931c-6b181cdb130c"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312f4b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2312f4b5",
    "outputId": "5ee6f28a-d06b-41bf-8194-600d91a07159"
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f5c71",
   "metadata": {
    "id": "819f5c71"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada5c03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ada5c03",
    "outputId": "960d424d-783c-45ca-bb04-0ed40f08c4f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df800071",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df800071",
    "outputId": "2969429a-c65a-48e6-a154-68a4aa0770e2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i,'   ' ,df[i].unique(), sep=\"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "252e0e9c",
   "metadata": {
    "id": "252e0e9c"
   },
   "source": [
    "# Id column doesnt provide any important information so better to delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183a231",
   "metadata": {
    "id": "3183a231"
   },
   "outputs": [],
   "source": [
    "df=df.drop(columns=['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb403d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "71fb403d",
    "outputId": "83973e8b-a92b-4eb6-dd33-48259421bfda",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fceea7",
   "metadata": {
    "id": "c2fceea7"
   },
   "source": [
    "##Feature Engineering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76680ad",
   "metadata": {
    "id": "f76680ad"
   },
   "source": [
    "#### creating a new column as age and droping Year_Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cdda3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a0cdda3",
    "outputId": "9bbd0903-714b-4751-f0cc-097b8657b02f"
   },
   "outputs": [],
   "source": [
    "df['Dt_Customer'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23b701",
   "metadata": {
    "id": "9f23b701"
   },
   "outputs": [],
   "source": [
    "# As the data we have is valid till 2014-2015 we can measure the age as\n",
    "df['Age']=2015-df['Year_Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b021f0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "3b021f0a",
    "outputId": "770d497e-200f-4ba8-9697-8dfe5b8eaa2f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ce382",
   "metadata": {
    "id": "ce9ce382"
   },
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Year_Birth'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c83db",
   "metadata": {
    "id": "5c1c83db"
   },
   "source": [
    "#### Modifying Educations column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1f1ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "f3f1f1ac",
    "outputId": "83a0fc3f-61ae-4bbd-9f32-8daa1a66575f"
   },
   "outputs": [],
   "source": [
    "df['Education'].value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7a9cf",
   "metadata": {
    "id": "66d7a9cf"
   },
   "outputs": [],
   "source": [
    "# We can make only three categories as Undergrad, Grad and Postgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1d134",
   "metadata": {
    "id": "cfb1d134"
   },
   "outputs": [],
   "source": [
    "df[\"Education\"]=df[\"Education\"].replace({\"Basic\":\"Undergraduate\",\"2n Cycle\":\"Undergraduate\", \"Graduation\":\"Graduate\", \"Master\":\"Postgraduate\", \"PhD\":\"Postgraduate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c23c0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99c23c0b",
    "outputId": "095d531a-a8a7-4112-85be-208ffe670388"
   },
   "outputs": [],
   "source": [
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6caa24",
   "metadata": {
    "id": "0f6caa24"
   },
   "source": [
    "#### Modifying Marital_Status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017bc08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "e017bc08",
    "outputId": "6ab557a8-41d4-4edc-86d8-581303613a0c"
   },
   "outputs": [],
   "source": [
    "df['Marital_Status'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a259f8",
   "metadata": {
    "id": "16a259f8"
   },
   "outputs": [],
   "source": [
    "# Lets keep two categories only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaca517",
   "metadata": {
    "id": "afaca517"
   },
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"]=df[\"Marital_Status\"].replace({\"Together\":\"Married\",\"Divorced\":\"Single\", \"Widow\":\"Single\",\"Alone\":\"Single\",\"Absurd\":\"Single\",\"YOLO\":\"Single\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba0f3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7ba0f3a",
    "outputId": "8953a74b-bda2-470a-9d2c-cc4f12b4377a"
   },
   "outputs": [],
   "source": [
    "df['Marital_Status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xCrHaGd8FqA8",
   "metadata": {
    "id": "xCrHaGd8FqA8"
   },
   "source": [
    "Converting Education and Marital status to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378bf81",
   "metadata": {
    "id": "1378bf81"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef69804",
   "metadata": {
    "id": "aef69804"
   },
   "outputs": [],
   "source": [
    "LE=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7b040",
   "metadata": {
    "id": "87f7b040"
   },
   "outputs": [],
   "source": [
    "df['Education']=LE.fit_transform(df['Education'])\n",
    "df['Marital_Status']=LE.fit_transform(df['Marital_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d5422",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "305d5422",
    "outputId": "c19623a8-7684-480f-e9a6-b921b08589c0"
   },
   "outputs": [],
   "source": [
    "df[['Education','Marital_Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7b4c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "9dc7b4c2",
    "outputId": "02f5b211-d6a8-450b-9caf-56f48aaa420f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78405a3d",
   "metadata": {
    "id": "78405a3d"
   },
   "source": [
    "#### removing Z_CostContact and Z_Revenue as the values throughout the columns are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd371e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbbd371e",
    "outputId": "c25854c0-cc42-420e-9bd1-928f85d0c5a9"
   },
   "outputs": [],
   "source": [
    "df[['Z_CostContact','Z_Revenue']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7a105",
   "metadata": {
    "id": "25c7a105"
   },
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Z_CostContact','Z_Revenue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9b39a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "38b9b39a",
    "outputId": "7c9fd52f-484e-4b7c-d818-325d930e5853",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0927d5b",
   "metadata": {
    "id": "d0927d5b"
   },
   "source": [
    "#### merging 'Kidhome' and 'Teenhome' into total_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe259b2",
   "metadata": {
    "id": "9fe259b2"
   },
   "outputs": [],
   "source": [
    "df['total_children']=df['Kidhome']+df['Teenhome']\n",
    "df= df.drop(columns=['Kidhome','Teenhome'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d1157",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "644d1157",
    "outputId": "8cccfd54-779d-4890-ae38-b468618414c8"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c259f",
   "metadata": {
    "id": "797c259f"
   },
   "source": [
    "#### Droping Date columns as it is not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55463f0a",
   "metadata": {
    "id": "55463f0a"
   },
   "outputs": [],
   "source": [
    "df= df.drop(columns=['Dt_Customer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ddc64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "f73ddc64",
    "outputId": "e94a1df0-37bb-45ba-cedd-a07d5e42c0a4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3270c39",
   "metadata": {
    "id": "c3270c39"
   },
   "source": [
    "#### separating categorical and numerical(continuous) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e41aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "520e41aa",
    "outputId": "bc759de1-ceaa-4344-cfd7-9123b1b0992f"
   },
   "outputs": [],
   "source": [
    "cat_columns=df[['Education','Marital_Status','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','AcceptedCmp1','AcceptedCmp2','Complain','Response']]\n",
    "cat_columns.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2faa3",
   "metadata": {
    "id": "fec2faa3"
   },
   "outputs": [],
   "source": [
    "num_columns=df.drop(columns=cat_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ff12d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "619ff12d",
    "outputId": "61582153-33ea-4f04-934c-11c379f1540e"
   },
   "outputs": [],
   "source": [
    "num_columns.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n-NGJWueXVA2",
   "metadata": {
    "id": "n-NGJWueXVA2"
   },
   "source": [
    "##Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ib_U6OMGXUXL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "ib_U6OMGXUXL",
    "outputId": "eff6c7e8-987e-47f8-881b-fecf93721959"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "df.hist(bins=30, figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ploWtYuYbUVy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "ploWtYuYbUVy",
    "outputId": "b4da0c1d-46f1-425e-a5b9-c4fe29228b10"
   },
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(df.select_dtypes(include=[np.number]).columns):\n",
    "    plt.subplot(5, 6, i+1)\n",
    "    sns.boxplot(df[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tBgbOj7kb0GV",
   "metadata": {
    "id": "tBgbOj7kb0GV"
   },
   "source": [
    "##Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R7K1NmLUblSp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R7K1NmLUblSp",
    "outputId": "3205a1eb-76b2-4872-ecac-60c2ac03b791"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6nIc5esJcD8E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6nIc5esJcD8E",
    "outputId": "f797d03d-88b8-406b-e0e5-27b9a07fb395"
   },
   "outputs": [],
   "source": [
    "# Count plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(df.select_dtypes(include=[object]).columns):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.countplot(y=col, data=df)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vx2CJgaVe8RV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "vx2CJgaVe8RV",
    "outputId": "4388c8fc-3435-41ec-9c5b-b056ca78e0a3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.swarmplot(x='NumWebPurchases', y='Income', data=df)\n",
    "plt.title('Income Distribution by Number of Web Purchases')\n",
    "plt.xlabel('Number of Web Purchases')\n",
    "plt.ylabel('Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B8ymVUsZfA3X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "B8ymVUsZfA3X",
    "outputId": "c68fdb71-f303-4603-ad2d-7b53071afc10"
   },
   "outputs": [],
   "source": [
    "df['Total_Spent'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Income', y='Total_Spent', data=df)\n",
    "plt.title('Income vs. Total Amount Spent')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Total Amount Spent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cp1Ng8hufE1i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Cp1Ng8hufE1i",
    "outputId": "376b0a18-40d1-417f-eab0-525545484543"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='Age', y='Recency', data=df)\n",
    "plt.title('Customer Recency by Year of Birth')\n",
    "plt.xlabel('Year of Birth')\n",
    "plt.ylabel('Recency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K-1AxJI8b5BO",
   "metadata": {
    "id": "K-1AxJI8b5BO"
   },
   "source": [
    "##Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qL2TUVC-bsjo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "qL2TUVC-bsjo",
    "outputId": "cd6a821f-1818-40c1-faac-26550bff10e9"
   },
   "outputs": [],
   "source": [
    "# Boxplots for numerical variables grouped by categorical variables\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(df.select_dtypes(include=[np.number]).columns):\n",
    "    plt.subplot(5, 6, i+1)\n",
    "    sns.boxplot(x='Education', y=col, data=df)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6YH8FKLbxdx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "e6YH8FKLbxdx",
    "outputId": "8efe48a5-921b-4579-9e2a-6a5235442118"
   },
   "outputs": [],
   "source": [
    "# Violin plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(df.select_dtypes(include=[np.number]).columns):\n",
    "    plt.subplot(5, 6, i+1)\n",
    "    sns.violinplot(x='Education', y=col, data=df)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365e337",
   "metadata": {
    "id": "5365e337"
   },
   "source": [
    "### Checking Skewness and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf33d09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bcf33d09",
    "outputId": "3d7eb61f-fffa-4100-c40c-bbd8231c5648"
   },
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    sns.histplot(df[col], kde=True)  # kde=True adds a KDE line to the histogram\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165722e",
   "metadata": {
    "id": "2165722e"
   },
   "source": [
    "##### Many of the columns are showing skewness and also possibilies of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d03d23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83d03d23",
    "outputId": "8d0d5fbc-7491-431e-dc4b-b2b97debf829",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f6560",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da6f6560",
    "outputId": "8f079db0-48e5-4b48-9bf7-2a9288d87092"
   },
   "outputs": [],
   "source": [
    "num_columns.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742ba76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2742ba76",
    "outputId": "18d51299-e13d-4bcf-ceaa-3394b5e99755",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcc2cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "02fcc2cc",
    "outputId": "3f2cacc7-b2f5-4b1c-db0a-c2734b2743f9"
   },
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    sns.scatterplot(df[col])\n",
    "    plt.title(f'scatterplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e1c22",
   "metadata": {
    "id": "643e1c22"
   },
   "outputs": [],
   "source": [
    "def detect_outliers(d):\n",
    "  for i in d:\n",
    "    Q3, Q1 = np.percentile(df[i], [75 ,25])\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper_bound = Q3+1.5*IQR\n",
    "    lower_bound = Q1-1.5*IQR\n",
    "\n",
    "    outliers = df[i][(df[i] > upper_bound) | (df[i] < lower_bound)]\n",
    "    print(f'*** {i} outlier points***', '\\n', outliers, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbbf16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15fbbf16",
    "outputId": "0d51b112-3c89-441c-f0ad-950398dfe500",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detect_outliers(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786389d",
   "metadata": {
    "id": "c786389d"
   },
   "source": [
    "#### Looking at the data , we can see that Income and age have genuine outliers and we have to delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064628bf",
   "metadata": {
    "id": "064628bf"
   },
   "outputs": [],
   "source": [
    "df = df[(df['Age']<100)]\n",
    "df = df[(df['Income']<150000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edeae98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0edeae98",
    "outputId": "0f8e7540-3b05-4f46-b08e-f26e40f43e53"
   },
   "outputs": [],
   "source": [
    "df[num_columns.columns].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501861a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "501861a9",
    "outputId": "8fa9f592-8735-4a61-f4eb-f3deb5accac2"
   },
   "outputs": [],
   "source": [
    "num_columns.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a71f28",
   "metadata": {
    "id": "50a71f28"
   },
   "source": [
    "#### performing log transformation to reduce skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e5bfe",
   "metadata": {
    "id": "996e5bfe"
   },
   "outputs": [],
   "source": [
    "skewed_features = ['MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases']\n",
    "for col in skewed_features:\n",
    "    df[col] = np.log1p(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5468c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de5468c0",
    "outputId": "1ed7da15-36e5-44ce-bec6-dd2aca5b2893"
   },
   "outputs": [],
   "source": [
    "df[num_columns.columns].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4c957",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aaf4c957",
    "outputId": "d426ad38-a5f2-48fd-bc47-3fb12cfd5228"
   },
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    sns.histplot(df[col], kde=True)  # kde=True adds a KDE line to the histogram\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad92b9d4",
   "metadata": {
    "id": "ad92b9d4"
   },
   "source": [
    "# Skewness has been controlled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62f442",
   "metadata": {
    "id": "2c62f442"
   },
   "source": [
    "##Multicollinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qb_2xpfR8Oft",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "Qb_2xpfR8Oft",
    "outputId": "cbd9f6aa-99ec-443d-9496-eca4262fb281"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBJKPUt98Ofu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBJKPUt98Ofu",
    "outputId": "08210993-3cc6-4599-b0c8-927643ba8819"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Add a constant term for VIF calculation\n",
    "df = add_constant(df)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"feature\"] = df.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "\n",
    "print(vif_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W-xAxbkiEUP3",
   "metadata": {
    "id": "W-xAxbkiEUP3"
   },
   "source": [
    "### all values less than 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ci7RlVBW8iK-",
   "metadata": {
    "id": "ci7RlVBW8iK-"
   },
   "source": [
    "###Scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf60f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "dcfcf60f",
    "outputId": "69b7aed8-6863-437f-9a66-91b3821826d9"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['PM2.5', 'PM10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80109d4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "80109d4e",
    "outputId": "4f0e7222-f6ca-4ab5-c12d-417e50d6028c"
   },
   "outputs": [],
   "source": [
    "data_cleaned=df.copy()\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee0ca8",
   "metadata": {
    "id": "9eee0ca8"
   },
   "outputs": [],
   "source": [
    "# Label encoding for categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5600d54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "e5600d54",
    "outputId": "b84ab284-c3d5-4c13-c24b-2b182fbbfc4e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84f01b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd84f01b",
    "outputId": "64a003f1-6732-4495-9664-a79759ed1f05"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bee48",
   "metadata": {
    "id": "2c4bee48"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2442168",
   "metadata": {
    "id": "c2442168"
   },
   "outputs": [],
   "source": [
    "df_scaled=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb874fd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fb874fd4",
    "outputId": "4febfa75-7792-40ab-ace4-382f642e566e"
   },
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29db8ac",
   "metadata": {
    "id": "f29db8ac"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d4f6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f8d4f6c",
    "outputId": "fbafc468-4764-4ce7-b03b-fc871719e5e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "pca_data = pd.DataFrame(pca.fit_transform(df_scaled))\n",
    "pca_data.columns = pca_data.columns.astype(str)\n",
    "print(f\"Number of components to explain 95% variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oV5DoId8GCp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "2oV5DoId8GCp",
    "outputId": "adc369ef-9842-4ea5-a1b0-2689e4645cbd"
   },
   "outputs": [],
   "source": [
    "pca_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lWxcXmra6aDk",
   "metadata": {
    "id": "lWxcXmra6aDk"
   },
   "source": [
    "###Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smYszGKk6MeR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "smYszGKk6MeR",
    "outputId": "f0261f19-7ccf-46f6-c8a2-2eda915d7d68"
   },
   "outputs": [],
   "source": [
    "# Calculate cumulative explained variance\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plotting explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(1, len(explained_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance by Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D0UdpaN26gCb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0UdpaN26gCb",
    "outputId": "95d74e2f-4f98-4b10-ffd1-297579903894"
   },
   "outputs": [],
   "source": [
    "# Print explained variance ratio for each component\n",
    "print(\"Explained Variance Ratio by Components:\")\n",
    "for i, ev in enumerate(explained_variance_ratio, start=1):\n",
    "    print(f\"Component {i}: {ev:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d051a",
   "metadata": {
    "id": "b15d051a"
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ddcd",
   "metadata": {
    "id": "5251ddcd"
   },
   "source": [
    "#### Elbow Method to find No of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242122c",
   "metadata": {
    "id": "e242122c"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a7c62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9a6a7c62",
    "outputId": "c921a411-a1d1-4a79-ec35-51b61588edb3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WCSS = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(pca_data)\n",
    "    WCSS.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Graph\n",
    "plt.plot(range(1, 11), WCSS, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58526f87",
   "metadata": {
    "id": "58526f87"
   },
   "source": [
    "#### Silhouette Score method to find out the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bcc83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "d11bcc83",
    "outputId": "da944210-6cd7-4680-9761-b2023ffd6cd7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(pca_data)\n",
    "    silhouette_scores.append(silhouette_score(pca_data, labels))\n",
    "\n",
    "# Plotting the Silhouette Scores\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4688a5",
   "metadata": {
    "id": "3e4688a5"
   },
   "outputs": [],
   "source": [
    "# high Silhouette Score indicates the best no of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e802f7d",
   "metadata": {
    "id": "0e802f7d"
   },
   "outputs": [],
   "source": [
    "# Although score of 2 clusters  is higher than 3 clusters ,\n",
    "# to make an effective strategy for marketing we will create 3 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6cb11a",
   "metadata": {
    "id": "8f6cb11a"
   },
   "source": [
    "## Number of Clusters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb47c61",
   "metadata": {
    "id": "5fb47c61"
   },
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "etl7rfts7hFB",
   "metadata": {
    "id": "etl7rfts7hFB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O3ZZhrX_7aj7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3ZZhrX_7aj7",
    "outputId": "ca7fc654-a733-40f3-bf84-96ec3d439fbb"
   },
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans_labels = kmeans.fit_predict(pca_data)\n",
    "\n",
    "# Evaluation Metrics\n",
    "kmeans_silhouette = silhouette_score(pca_data, kmeans_labels)\n",
    "kmeans_db_index = davies_bouldin_score(pca_data, kmeans_labels)\n",
    "kmeans_ch_index = calinski_harabasz_score(pca_data, kmeans_labels)\n",
    "\n",
    "print(f\"K-Means Clustering Metrics:\")\n",
    "print(f\"Silhouette Score: {kmeans_silhouette:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {kmeans_db_index:.4f}\")\n",
    "print(f\"Calinski-Harabasz Index: {kmeans_ch_index:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2LmZS3iohvzk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "2LmZS3iohvzk",
    "outputId": "41f9d3f3-ed5a-4d64-8a47-081a5bb8a4cf"
   },
   "outputs": [],
   "source": [
    "# Plotting K-Means Clustering Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_data.iloc[:, 0], y=pca_data.iloc[:, 1], hue=kmeans_labels, palette='viridis')\n",
    "plt.title('K-Means Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5NlzT63nwia",
   "metadata": {
    "id": "s5NlzT63nwia"
   },
   "source": [
    "###Agglomerative (or) Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98AO91oS-TZ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "98AO91oS-TZ0",
    "outputId": "9fd89c17-e12a-4d09-c228-e4665b829a13"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "\n",
    "linked = shc.linkage(pca_data, method='ward')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "shc.dendrogram(linked)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# Fit Agglomerative Clustering\n",
    "agg_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "labels = agg_cluster.fit_predict(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3Ea3vRs-hLE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3Ea3vRs-hLE",
    "outputId": "79b18d4c-0bd7-4038-8b6a-c54fd63a3b59"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Hierarchical Clustering with optimal clusters\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "hierarchical_labels = hierarchical.fit_predict(pca_data)\n",
    "\n",
    "# Evaluation Metrics\n",
    "hierarchical_silhouette = silhouette_score(pca_data, hierarchical_labels)\n",
    "hierarchical_db_index = davies_bouldin_score(pca_data, hierarchical_labels)\n",
    "hierarchical_ch_index = calinski_harabasz_score(pca_data, hierarchical_labels)\n",
    "\n",
    "print(f\"Hierarchical Clustering Metrics:\")\n",
    "print(f\"Silhouette Score: {hierarchical_silhouette:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {hierarchical_db_index:.4f}\")\n",
    "print(f\"Calinski-Harabasz Index: {hierarchical_ch_index:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EcuL8AJ8h-JY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "EcuL8AJ8h-JY",
    "outputId": "d590fc20-9fba-49da-dfdb-b4a889853e5f"
   },
   "outputs": [],
   "source": [
    "# Plotting Hierarchical Clustering Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_data.iloc[:, 0], y=pca_data.iloc[:, 1], hue=hierarchical_labels, palette='viridis')\n",
    "plt.title('Hierarchical Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XHdpx1pkpcWf",
   "metadata": {
    "id": "XHdpx1pkpcWf"
   },
   "source": [
    "### Gaussian Mixture Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OaHYMTAI8gFp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaHYMTAI8gFp",
    "outputId": "01a0d4e2-d848-46b8-f27f-3e122756af00"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Gaussian Mixture with optimal clusters (e.g., k=4)\n",
    "gmm = GaussianMixture(n_components=3, random_state=0)\n",
    "gmm_labels = gmm.fit_predict(pca_data)\n",
    "\n",
    "# Evaluation Metrics\n",
    "gaussian_silhouette = silhouette_score(pca_data, gmm_labels)\n",
    "gaussian_db_index = davies_bouldin_score(pca_data, gmm_labels)\n",
    "gaussian_ch_index = calinski_harabasz_score(pca_data, gmm_labels)\n",
    "\n",
    "print(f\"Gaussian Mixture Metrics:\")\n",
    "print(f\"Silhouette Score: {gaussian_silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {gaussian_db_index}\")\n",
    "print(f\"Calinski-Harabasz Index: {gaussian_ch_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DqNBNlqNibzg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "DqNBNlqNibzg",
    "outputId": "af5a8fbd-cc91-4640-ac75-fe08695d18f8"
   },
   "outputs": [],
   "source": [
    "# Plotting Gaussian Mixture Clustering Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_data.iloc[:, 0], y=pca_data.iloc[:, 1], hue=gmm_labels, palette='viridis')\n",
    "plt.title('Gaussian Mixture Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pr9gX_f-n9Z0",
   "metadata": {
    "id": "Pr9gX_f-n9Z0"
   },
   "source": [
    "###DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T44n74twp-s5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "T44n74twp-s5",
    "outputId": "0e231bda-7452-484e-ce81-407a1c951aec"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Find the best eps and min_samples for DBSCAN using Grid Search\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=11)\n",
    "nearest_neighbors.fit(pca_data)\n",
    "distances, indices = nearest_neighbors.kneighbors(pca_data)\n",
    "distances = np.sort(distances[:, 10], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.title('K-distance Graph for DBSCAN')\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel('10th nearest neighbor distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7U58HiKqVgl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7U58HiKqVgl",
    "outputId": "3ee7a233-072c-4389-9107-fcba335e4bf1"
   },
   "outputs": [],
   "source": [
    "# Based on the graph, let's choose an eps value where the slope changes sharply\n",
    "best_eps = 1.5\n",
    "best_min_samples = 10\n",
    "\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "dbscan_labels = dbscan.fit_predict(pca_data)\n",
    "\n",
    "# Filter out noise points (-1 labels) for evaluation\n",
    "dbscan_valid_data = pca_data[dbscan_labels != -1]\n",
    "dbscan_valid_labels = dbscan_labels[dbscan_labels != -1]\n",
    "\n",
    "# Evaluation Metrics for DBSCAN\n",
    "dbscan_silhouette = silhouette_score(dbscan_valid_data, dbscan_valid_labels)\n",
    "dbscan_db_index = davies_bouldin_score(dbscan_valid_data, dbscan_valid_labels)\n",
    "dbscan_ch_index = calinski_harabasz_score(dbscan_valid_data, dbscan_valid_labels)\n",
    "\n",
    "\n",
    "print(f\"DBSCAN Clustering Metrics:\")\n",
    "print(f\"Silhouette Score: {dbscan_silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {dbscan_db_index}\")\n",
    "print(f\"Calinski-Harabasz Index: {dbscan_ch_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eMDZgkzJqaA-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "eMDZgkzJqaA-",
    "outputId": "632bbee4-9355-4fe4-c7e8-e8f662dbdceb"
   },
   "outputs": [],
   "source": [
    "# Plotting DBSCAN Clustering Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=dbscan_valid_data.iloc[:, 0], y=dbscan_valid_data.iloc[:, 1], hue=dbscan_valid_labels, palette='viridis')\n",
    "plt.title('DBSCAN Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HNXym-XPpri3",
   "metadata": {
    "id": "HNXym-XPpri3"
   },
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_h5A2wLsrsfn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_h5A2wLsrsfn",
    "outputId": "c8589a0d-79e0-4586-ca5d-a0d24965d763"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Spectral Clustering\n",
    "n_clusters = 3  # You can specify the number of clusters you want\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', random_state=0)\n",
    "spectral_labels = spectral.fit_predict(pca_data)\n",
    "\n",
    "# Evaluation Metrics for Spectral Clustering\n",
    "spectral_silhouette = silhouette_score(pca_data, spectral_labels)\n",
    "spectral_db_index = davies_bouldin_score(pca_data, spectral_labels)\n",
    "spectral_ch_index = calinski_harabasz_score(pca_data, spectral_labels)\n",
    "\n",
    "print(f\"Spectral Clustering Metrics:\")\n",
    "print(f\"Silhouette Score: {spectral_silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {spectral_db_index}\")\n",
    "print(f\"Calinski-Harabasz Index: {spectral_ch_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2kKymjTxsBlI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "2kKymjTxsBlI",
    "outputId": "0bbdad97-76ad-4526-8a63-1e23123c24a5"
   },
   "outputs": [],
   "source": [
    "# Plotting Spectral Clustering Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_data.iloc[:, 0], y=pca_data.iloc[:, 1], hue=spectral_labels, palette='viridis')\n",
    "plt.title('Spectral Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wh4lZ5mHshpj",
   "metadata": {
    "id": "Wh4lZ5mHshpj"
   },
   "source": [
    "###Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H6xdKWqOCuj_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6xdKWqOCuj_",
    "outputId": "58fd24cd-e6ce-4362-b112-944162e78c77"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming you have calculated metrics and stored them in variables like this\n",
    "clustering_algorithms = [\"K-Means\", \"Hierarchical\", \"DBSCAN\", \"Gaussian Mixture\", \"Spectral Clustering\"]\n",
    "silhouette_scores = [kmeans_silhouette, hierarchical_silhouette, dbscan_silhouette, gaussian_silhouette, spectral_silhouette]\n",
    "db_indices = [kmeans_db_index, hierarchical_db_index, dbscan_db_index, gaussian_db_index, spectral_db_index]\n",
    "ch_indices = [kmeans_ch_index, hierarchical_ch_index, dbscan_ch_index, gaussian_ch_index, spectral_ch_index]\n",
    "\n",
    "# Create a dictionary for DataFrame\n",
    "data = {\n",
    "    \"Clustering Algorithm\": clustering_algorithms,\n",
    "    \"Silhouette Score\": silhouette_scores,\n",
    "    \"Davies-Bouldin Index\": db_indices,\n",
    "    \"Calinski-Harabasz Index\": ch_indices\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate composite score (higher is better)\n",
    "results_df['Composite Score'] = results_df['Silhouette Score'] - results_df['Davies-Bouldin Index'] + results_df['Calinski-Harabasz Index']\n",
    "\n",
    "# Print the table using tabulate\n",
    "table = tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False)\n",
    "print(table)\n",
    "\n",
    "# Determine the best clustering algorithm based on Composite Score\n",
    "best_clustering_algorithm = results_df.loc[results_df['Composite Score'].idxmax(), 'Clustering Algorithm']\n",
    "print(\"\\nBest Clustering Technique based on Composite Score:\")\n",
    "print(best_clustering_algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rT7fOXZfx5Hs",
   "metadata": {
    "id": "rT7fOXZfx5Hs"
   },
   "source": [
    "##Kmeans Clustering is the best suited for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf5adb",
   "metadata": {
    "id": "09bf5adb"
   },
   "source": [
    "# Profiling and Analysis Of Clusters using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c254ce7",
   "metadata": {
    "id": "2c254ce7"
   },
   "outputs": [],
   "source": [
    "data_cleaned['Clusters']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b543d",
   "metadata": {
    "id": "416b543d"
   },
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "cluster_map = {0: 'group 1', 1: 'group 2', 2: 'group 3'}\n",
    "\n",
    "# Applying map function\n",
    "data_cleaned['Cluster_group'] = data_cleaned['Clusters'].map(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8ae68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "a3e8ae68",
    "outputId": "7529f653-8098-4b24-c833-eb611ed579dc"
   },
   "outputs": [],
   "source": [
    "data_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vGezJbU61uwh",
   "metadata": {
    "id": "vGezJbU61uwh"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans_labels = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "df['KMeans_Cluster'] = kmeans_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5YCvTmUq1nMI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YCvTmUq1nMI",
    "outputId": "83461a44-d958-4925-b788-0308a3db4a63"
   },
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics for hierarchical clusters\n",
    "kmeans_stats = df.groupby('KMeans_Cluster').agg(['mean', 'median', 'std'])\n",
    "print(\"Hierarchical Clusters Descriptive Statistics:\")\n",
    "print(kmeans_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZDEo4dP011xK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZDEo4dP011xK",
    "outputId": "9a1f206a-9a2d-4494-ffed-3abd0a2382ae"
   },
   "outputs": [],
   "source": [
    "# Function to plot feature distribution within K-Means clusters\n",
    "def plot_kmeans_cluster_distribution(df, cluster_column, title):\n",
    "    for feature in df.columns[:-3]:  # Exclude the last three cluster columns\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x=cluster_column, y=feature, data=df)\n",
    "        plt.title(f\"{title} - {feature}\")\n",
    "        plt.show()\n",
    "\n",
    "# Plot feature distribution within K-Means clusters\n",
    "plot_kmeans_cluster_distribution(df, 'KMeans_Cluster', 'K-Means Clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hgX7vduhoVlR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgX7vduhoVlR",
    "outputId": "4d59165e-bafc-4a75-ce32-2bb77dbbdc71"
   },
   "outputs": [],
   "source": [
    "data_cleaned['Cluster_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9565dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9a9565dc",
    "outputId": "219f20c6-144d-4049-f583-43d71ca21cbf"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data_cleaned['Cluster_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6bd9b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ea6bd9b6",
    "outputId": "0a72c24d-4207-4225-9fbc-f4510e3ad652"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data_cleaned['Cluster_group'],hue=data_cleaned['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c84a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "af0c84a1",
    "outputId": "bcb73f1b-20df-4ce4-e8ac-f938e7b359d5"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data_cleaned['Cluster_group'],hue=data_cleaned['Marital_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d59a13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "78d59a13",
    "outputId": "1ce8e973-57a8-4fdd-cfe5-29f43105ca01"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data = data_cleaned, x=data_cleaned[\"Income\"],hue=data_cleaned[\"Cluster_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec8f71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cec8f71",
    "outputId": "fae71edc-7ff5-4a6f-a951-e02581c3c000"
   },
   "outputs": [],
   "source": [
    "cluster_income_summary = data_cleaned.groupby('Cluster_group')['Income'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "print(cluster_income_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f53695",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "21f53695",
    "outputId": "70b5a78a-a376-47e7-8e56-e55430829c33"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data = data_cleaned, x=data_cleaned[\"Age\"],hue=data_cleaned[\"Cluster_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a3700",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "307a3700",
    "outputId": "9ea8ac31-b83d-4e47-d954-2720e78876ad"
   },
   "outputs": [],
   "source": [
    "cluster_age_summary = data_cleaned.groupby('Cluster_group')['Age'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "print(cluster_age_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dece5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "363dece5",
    "outputId": "da98cd0a-bd09-425a-8244-af2797075c10"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data_cleaned['Cluster_group'],hue=data_cleaned['total_children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a69149",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "f8a69149",
    "outputId": "4fccb6de-1d05-49df-d4b7-1da5ec7ead49"
   },
   "outputs": [],
   "source": [
    "#Creating a feature to get a sum of spendings\n",
    "\n",
    "data_cleaned[\"Total_spend\"] = data_cleaned[\"MntWines\"]+ data_cleaned[\"MntFruits\"]+ data_cleaned[\"MntMeatProducts\"]+ data_cleaned[\"MntFishProducts\"]+ data_cleaned[\"MntSweetProducts\"]+data_cleaned[\"MntGoldProds\"]\n",
    "\n",
    "#Plotting count of total campaign accepted.\n",
    "\n",
    "plt.figure()\n",
    "data_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e7ee1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "c48e7ee1",
    "outputId": "0aa156ed-7002-4dc3-ef7c-ae3ac85993e2"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = data_cleaned ,x=data_cleaned[\"Total_spend\"], y=data_cleaned[\"Income\"],hue=data_cleaned[\"Clusters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f506a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "c0f506a4",
    "outputId": "990c4436-69fc-4f7b-b1dd-e90d7afd783b"
   },
   "outputs": [],
   "source": [
    "#Creating a feature to get total number of purchases made\n",
    "\n",
    "data_cleaned[\"Total_purchase\"] = data_cleaned[\"NumDealsPurchases\"]+ data_cleaned[\"NumWebPurchases\"]+ data_cleaned[\"NumCatalogPurchases\"]+data_cleaned[\"NumStorePurchases\"]\n",
    "\n",
    "#Plotting count of total campaign accepted.\n",
    "\n",
    "plt.figure()\n",
    "data_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa3558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "11fa3558",
    "outputId": "f7165c2f-39a3-4282-e2ca-d2e964ae850b"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = data_cleaned ,x=data_cleaned[\"Total_purchase\"], y=data_cleaned[\"Income\"],hue=data_cleaned[\"Clusters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706c02a",
   "metadata": {
    "id": "8706c02a"
   },
   "source": [
    "# Classification for future Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf4de4",
   "metadata": {
    "id": "7baf4de4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2decc065",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "2decc065",
    "outputId": "eaf3915a-a483-4d18-c2d6-c184bd8d367b"
   },
   "outputs": [],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca145d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ca145d8",
    "outputId": "8606859f-9f04-46dc-f72c-9ea8a16574f6"
   },
   "outputs": [],
   "source": [
    "data_cleaned['Complain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fb96c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af6fb96c",
    "outputId": "a947bfa4-78f9-4357-826c-dd064faddb34"
   },
   "outputs": [],
   "source": [
    "data_cleaned['Response'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b79a8",
   "metadata": {
    "id": "424b79a8"
   },
   "outputs": [],
   "source": [
    "classif_data=data_cleaned.drop(columns=['Cluster_group','Total_spend','Total_purchase','Complain','Response','Recency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf7019",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fdcf7019",
    "outputId": "bbb4d5fe-c6d3-4929-f222-f105145ecb4f"
   },
   "outputs": [],
   "source": [
    "classif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a313c",
   "metadata": {
    "id": "464a313c"
   },
   "outputs": [],
   "source": [
    "classif_data['Education']=LE.fit_transform(classif_data['Education'])\n",
    "classif_data['Marital_Status']=LE.fit_transform(classif_data['Marital_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b66d7",
   "metadata": {
    "id": "519b66d7"
   },
   "outputs": [],
   "source": [
    "classif_scaled=pd.DataFrame(scaler.fit_transform(classif_data),columns=classif_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849fd20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "9849fd20",
    "outputId": "63972b30-6318-4fb4-c4a5-204b66e30e6a"
   },
   "outputs": [],
   "source": [
    "classif_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67b924",
   "metadata": {
    "id": "8c67b924"
   },
   "outputs": [],
   "source": [
    "X=classif_data.drop('Clusters',axis=1)\n",
    "y=classif_data['Clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e4f36",
   "metadata": {
    "id": "717e4f36"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OtP6nMDbJ5V5",
   "metadata": {
    "id": "OtP6nMDbJ5V5"
   },
   "source": [
    "##Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oz9yam87JHNF",
   "metadata": {
    "id": "Oz9yam87JHNF"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import  accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Odn9V1qqM5oX",
   "metadata": {
    "id": "Odn9V1qqM5oX"
   },
   "source": [
    "###Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HSe8o5QsKcE2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSe8o5QsKcE2",
    "outputId": "e55bf678-504c-4bf5-9b65-6c29b008e3ba"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Training the model\n",
    "logreg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred)\n",
    "logreg_precision = precision_score(y_test, y_pred, average='macro')\n",
    "logreg_recall = recall_score(y_test, y_pred, average='macro')\n",
    "logreg_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "logreg_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "logreg_logloss = log_loss(y_test, y_pred_proba)\n",
    "logreg_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {logreg_accuracy}')\n",
    "print(f'Precision: {logreg_precision}')\n",
    "print(f'Recall: {logreg_recall}')\n",
    "print(f'F1 Score: {logreg_f1}')\n",
    "print(f'ROC-AUC Score: {logreg_roc_auc}')\n",
    "print(f'Log Loss: {logreg_logloss}')\n",
    "print(f'Confusion Matrix:\\n {logreg_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rDNR4jWyLGEc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "rDNR4jWyLGEc",
    "outputId": "f8db7883-ff4d-458c-e58c-f8b0cac9efbb"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "n_classes = len(logreg.classes_)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KJkmb4TONTXa",
   "metadata": {
    "id": "KJkmb4TONTXa"
   },
   "source": [
    "###KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqplkylPNS9K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqplkylPNS9K",
    "outputId": "103b6f2e-8644-4c0e-cadc-27429a75ed6b"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Training the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_proba = knn.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_precision = precision_score(y_test, y_pred, average='macro')\n",
    "knn_recall = recall_score(y_test, y_pred, average='macro')\n",
    "knn_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "knn_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "knn_logloss = log_loss(y_test, y_pred_proba)\n",
    "knn_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {knn_accuracy}')\n",
    "print(f'Precision: {knn_precision}')\n",
    "print(f'Recall: {knn_recall}')\n",
    "print(f'F1 Score: {knn_f1}')\n",
    "print(f'ROC-AUC Score: {knn_roc_auc}')\n",
    "print(f'Log Loss: {knn_logloss}')\n",
    "print(f'Confusion Matrix:\\n {knn_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dv6YjBvENoW3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "dv6YjBvENoW3",
    "outputId": "9f3a74e7-3ffe-4c79-b92f-dd1907eb6010"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "n_classes = len(knn.classes_)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPX9muLO1x0",
   "metadata": {
    "id": "qZPX9muLO1x0"
   },
   "source": [
    "###Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5b98b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28c5b98b",
    "outputId": "edbe70c0-6a43-4df3-9df6-b617a889cd17"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Training the Decision Tree model\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = dtc.predict(X_test)\n",
    "y_pred_proba = dtc.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "dtc_accuracy = accuracy_score(y_test, y_pred)\n",
    "dtc_precision = precision_score(y_test, y_pred, average='macro')\n",
    "dtc_recall = recall_score(y_test, y_pred, average='macro')\n",
    "dtc_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "dtc_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "dtc_logloss = log_loss(y_test, y_pred_proba)\n",
    "dtc_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {dtc_accuracy}')\n",
    "print(f'Precision: {dtc_precision}')\n",
    "print(f'Recall: {dtc_recall}')\n",
    "print(f'F1 Score: {dtc_f1}')\n",
    "print(f'ROC-AUC Score: {dtc_roc_auc}')\n",
    "print(f'Log Loss: {dtc_logloss}')\n",
    "print(f'Confusion Matrix:\\n {dtc_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IQwUKxg_PHV5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "IQwUKxg_PHV5",
    "outputId": "cdeb04d9-af05-4f50-b955-1d588cac3242"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "n_classes = len(dtc.classes_)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tCopricoP8Mw",
   "metadata": {
    "id": "tCopricoP8Mw"
   },
   "source": [
    "###Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qSZ8zORyPL0M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSZ8zORyPL0M",
    "outputId": "188e3ae6-5f72-4fe7-a7ca-72acecade629"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Training the Random Forest model\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_pred_proba = rfc.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "rfc_accuracy = accuracy_score(y_test, y_pred)\n",
    "rfc_precision = precision_score(y_test, y_pred, average='macro')\n",
    "rfc_recall = recall_score(y_test, y_pred, average='macro')\n",
    "rfc_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "rfc_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "rfc_logloss = log_loss(y_test, y_pred_proba)\n",
    "rfc_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {rfc_accuracy}')\n",
    "print(f'Precision: {rfc_precision}')\n",
    "print(f'Recall: {rfc_recall}')\n",
    "print(f'F1 Score: {rfc_f1}')\n",
    "print(f'ROC-AUC Score: {rfc_roc_auc}')\n",
    "print(f'Log Loss: {rfc_logloss}')\n",
    "print(f'Confusion Matrix:\\n {rfc_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7KTJQaLEPLmU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "7KTJQaLEPLmU",
    "outputId": "68f182bc-1fb0-454d-a190-7620302c6ed8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "n_classes = len(rfc.classes_)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnGYZJnY0R0n",
   "metadata": {
    "id": "qnGYZJnY0R0n"
   },
   "source": [
    "###SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ydCyZAJH0Rb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydCyZAJH0Rb6",
    "outputId": "f5cd45c6-ba5a-47ce-af17-11bb24ffecf1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the output\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])  # Adjust classes as necessary\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the SVM model with One-vs-Rest strategy\n",
    "svm = OneVsRestClassifier(SVC(probability=True, random_state=42))\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "y_pred_proba = svm.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_precision = precision_score(y_test, y_pred, average='macro')\n",
    "svm_recall = recall_score(y_test, y_pred, average='macro')\n",
    "svm_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "svm_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "svm_logloss = log_loss(y_test, y_pred_proba)\n",
    "svm_conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "print(f'Accuracy: {svm_accuracy}')\n",
    "print(f'Precision: {svm_precision}')\n",
    "print(f'Recall: {svm_recall}')\n",
    "print(f'F1 Score: {svm_f1}')\n",
    "print(f'ROC-AUC Score: {svm_roc_auc}')\n",
    "print(f'Log Loss: {svm_logloss}')\n",
    "print(f'Confusion Matrix:\\n {svm_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5_diBq622Wq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "i5_diBq622Wq",
    "outputId": "ef4eb049-c37b-458a-b524-6a463a9baa2c"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O1k3dAZH4MGJ",
   "metadata": {
    "id": "O1k3dAZH4MGJ"
   },
   "source": [
    "###Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KItBgFL84Lxk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KItBgFL84Lxk",
    "outputId": "07bca8ff-3222-4798-a01b-edb6c2445625"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the output\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])  # Adjust classes as necessary\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train.argmax(axis=1))  # Training on the original multiclass labels\n",
    "\n",
    "# Making predictions\n",
    "y_pred = gb.predict(X_test)\n",
    "y_pred_proba = gb.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "gb_accuracy = accuracy_score(y_test.argmax(axis=1), y_pred)\n",
    "gb_precision = precision_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "gb_recall = recall_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "gb_f1 = f1_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "gb_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "gb_logloss = log_loss(y_test, y_pred_proba)\n",
    "gb_conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "print(f'Accuracy: {gb_accuracy}')\n",
    "print(f'Precision: {gb_precision}')\n",
    "print(f'Recall: {gb_recall}')\n",
    "print(f'F1 Score: {gb_f1}')\n",
    "print(f'ROC-AUC Score: {gb_roc_auc}')\n",
    "print(f'Log Loss: {gb_logloss}')\n",
    "print(f'Confusion Matrix:\\n {gb_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3OJuQqBTF4ml",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "3OJuQqBTF4ml",
    "outputId": "34b03d50-44e9-4e89-80d6-988e6d71ad71"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LZbYDLtqGSC-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "LZbYDLtqGSC-",
    "outputId": "1e2b1f42-7362-47ea-833a-45f70e7041dc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the output\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])  # Adjust classes as necessary\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Naive Bayes Classifier\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train.argmax(axis=1))  # Training on the original multiclass labels\n",
    "\n",
    "# Making predictions\n",
    "y_pred = nb.predict(X_test)\n",
    "y_pred_proba = nb.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "nb_accuracy = accuracy_score(y_test.argmax(axis=1), y_pred)\n",
    "nb_precision = precision_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "nb_recall = recall_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "nb_f1 = f1_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "nb_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "nb_logloss = log_loss(y_test, y_pred_proba)\n",
    "nb_conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "print(f'Accuracy: {nb_accuracy}')\n",
    "print(f'Precision: {nb_precision}')\n",
    "print(f'Recall: {nb_recall}')\n",
    "print(f'F1 Score: {nb_f1}')\n",
    "print(f'ROC-AUC Score: {nb_roc_auc}')\n",
    "print(f'Log Loss: {nb_logloss}')\n",
    "print(f'Confusion Matrix:\\n {nb_conf_matrix}')\n",
    "\n",
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xskiuO4rHvBk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xskiuO4rHvBk",
    "outputId": "f6219e3d-8e74-4c0c-b9a0-be1a5b7e9369"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the output for multiclass ROC AUC\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])  # Adjust classes as necessary\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train.argmax(axis=1))  # Training on the original multiclass labels\n",
    "\n",
    "# Making predictions\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "xgb_accuracy = accuracy_score(y_test.argmax(axis=1), y_pred)\n",
    "xgb_precision = precision_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "xgb_recall = recall_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "xgb_f1 = f1_score(y_test.argmax(axis=1), y_pred, average='macro')\n",
    "xgb_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "xgb_logloss = log_loss(y_test, y_pred_proba)\n",
    "xgb_conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "print(f'Accuracy: {xgb_accuracy}')\n",
    "print(f'Precision: {xgb_precision}')\n",
    "print(f'Recall: {xgb_recall}')\n",
    "print(f'F1 Score: {xgb_f1}')\n",
    "print(f'ROC-AUC Score: {xgb_roc_auc}')\n",
    "print(f'Log Loss: {xgb_logloss}')\n",
    "print(f'Confusion Matrix:\\n {xgb_conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64NZNh-9H72Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "64NZNh-9H72Q",
    "outputId": "3eb14326-1bc5-463d-fc78-6c9d8ec07f06"
   },
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve for multiclass\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting all ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'green', 'red']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hL0gccW6IK6h",
   "metadata": {
    "id": "hL0gccW6IK6h"
   },
   "source": [
    "##Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bQsq1KSWotr4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQsq1KSWotr4",
    "outputId": "556c1e47-03f7-4260-a19a-fcf85400e6fb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define your model names and corresponding classification metrics\n",
    "models = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"XGBoost\",\n",
    "          \"KNN\", \"SVM\", \"Naive Bayes\"]\n",
    "accuracy = [logreg_accuracy, dtc_accuracy, rfc_accuracy, gb_accuracy, xgb_accuracy,\n",
    "            knn_accuracy, svm_accuracy, nb_accuracy]\n",
    "precision = [logreg_precision, dtc_precision, rfc_precision, gb_precision, xgb_precision,\n",
    "             knn_precision, svm_precision, nb_precision]\n",
    "recall = [logreg_recall, dtc_recall, rfc_recall, gb_recall, xgb_recall,\n",
    "          knn_recall, svm_recall, nb_recall]\n",
    "f1_score = [logreg_f1, dtc_f1, rfc_f1, gb_f1, xgb_f1,\n",
    "            knn_f1, svm_f1, nb_f1]\n",
    "roc_auc = [logreg_roc_auc, dtc_roc_auc, rfc_roc_auc, gb_roc_auc, xgb_roc_auc,\n",
    "           knn_roc_auc, svm_roc_auc, nb_roc_auc]\n",
    "log_loss = [logreg_logloss, dtc_logloss, rfc_logloss, gb_logloss, xgb_logloss,\n",
    "            knn_logloss, svm_logloss, nb_logloss]\n",
    "confusion_matrix = [logreg_conf_matrix, dtc_conf_matrix, rfc_conf_matrix, gb_conf_matrix, xgb_conf_matrix,\n",
    "                    knn_conf_matrix, svm_conf_matrix, nb_conf_matrix]\n",
    "\n",
    "# Create the dictionary for DataFrame\n",
    "data = {\n",
    "    \"Model\": models,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1 Score\": f1_score,\n",
    "    \"ROC AUC\": roc_auc,\n",
    "    \"Log Loss\": log_loss,\n",
    "    \"Confusion Matrix\": confusion_matrix\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the table using tabulate\n",
    "table = tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False)\n",
    "\n",
    "# Print the formatted table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BWUZhHKHo1-r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWUZhHKHo1-r",
    "outputId": "15b1051e-0d48-45e5-ece9-7d9b11350899"
   },
   "outputs": [],
   "source": [
    "# Find the best models based on Accuracy\n",
    "best_models_accuracy = results_df[results_df['Accuracy'] == results_df['Accuracy'].max()]\n",
    "\n",
    "print(\"\\nModels with the highest Accuracy:\")\n",
    "print(best_models_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QDyXQM3Dpedm",
   "metadata": {
    "id": "QDyXQM3Dpedm"
   },
   "source": [
    "###since we have two best model according to the accuracy, there is a need to compare other metrics too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MsXMnBMZpRFn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsXMnBMZpRFn",
    "outputId": "1c1af88d-1f69-4305-e04c-2a05f8d6942e"
   },
   "outputs": [],
   "source": [
    "# Compare other metrics for these models\n",
    "for index, row in best_models_accuracy.iterrows():\n",
    "    model_name = row['Model']\n",
    "    print(f\"\\nPerformance metrics for {model_name}:\")\n",
    "    print(f\"Precision: {row['Precision']}\")\n",
    "    print(f\"Recall: {row['Recall']}\")\n",
    "    print(f\"F1 Score: {row['F1 Score']}\")\n",
    "    print(f\"ROC AUC: {row['ROC AUC']}\")\n",
    "    print(f\"Log Loss: {row['Log Loss']}\")\n",
    "    print(f\"Confusion Matrix: {row['Confusion Matrix']}\")\n",
    "\n",
    "# Find the best model based on each metric\n",
    "best_model_f1 = best_models_accuracy['F1 Score'].idxmax()\n",
    "best_model_log_loss = best_models_accuracy['Log Loss'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rti-sz8Dq1ig",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rti-sz8Dq1ig",
    "outputId": "8e6e0d55-0b81-4b44-e598-6a9eee515c10"
   },
   "outputs": [],
   "source": [
    "# Print the best model for each metric\n",
    "print(\"\\nBest model based on F1 Score:\")\n",
    "print(best_models_accuracy.loc[best_model_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4nTlgJMKwnQ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nTlgJMKwnQ0",
    "outputId": "fe1600a3-d902-4409-bae0-89ef4c8e431c"
   },
   "outputs": [],
   "source": [
    "print(\"\\nBest model based on Log Loss:\")\n",
    "print(best_models_accuracy.loc[best_model_log_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76sdd4KMxYSe",
   "metadata": {
    "id": "76sdd4KMxYSe"
   },
   "source": [
    "##Therefore Random Forest achieves the best when compared to XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21EnYei4w4pE",
   "metadata": {
    "id": "21EnYei4w4pE"
   },
   "source": [
    "#Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foIDfip_x_eu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foIDfip_x_eu",
    "outputId": "255ef19c-c792-46d7-dae9-1b8065f20537"
   },
   "outputs": [],
   "source": [
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yE0AmjwIyunS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE0AmjwIyunS",
    "outputId": "fde0b566-f7b9-4677-b81a-723b0b95b50b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# Setting display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reading the data\n",
    "df = pd.read_excel(\"marketing_campaign.xlsx\")\n",
    "\n",
    "# Basic data inspection\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Dropping rows with missing values\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum())\n",
    "print(df.shape)\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "df = df.drop(columns=['ID'], axis=1)\n",
    "\n",
    "# Creating age column and dropping Year_Birth\n",
    "df['Age'] = 2015 - df['Year_Birth']\n",
    "df = df.drop(columns=['Year_Birth'], axis=1)\n",
    "\n",
    "# Modifying Education column\n",
    "df[\"Education\"] = df[\"Education\"].replace({\"Basic\": \"Undergraduate\", \"2n Cycle\": \"Undergraduate\",\n",
    "                                           \"Graduation\": \"Graduate\", \"Master\": \"Postgraduate\",\n",
    "                                           \"PhD\": \"Postgraduate\"})\n",
    "\n",
    "# Modifying Marital_Status column\n",
    "df[\"Marital_Status\"] = df[\"Marital_Status\"].replace({\"Together\": \"Married\", \"Divorced\": \"Single\",\n",
    "                                                     \"Widow\": \"Single\", \"Alone\": \"Single\",\n",
    "                                                     \"Absurd\": \"Single\", \"YOLO\": \"Single\"})\n",
    "\n",
    "# Dropping Z_CostContact and Z_Revenue columns\n",
    "df = df.drop(columns=['Z_CostContact', 'Z_Revenue'], axis=1)\n",
    "\n",
    "# Merging Kidhome and Teenhome into total_children\n",
    "df['total_children'] = df['Kidhome'] + df['Teenhome']\n",
    "df = df.drop(columns=['Kidhome', 'Teenhome'], axis=1)\n",
    "\n",
    "# Dropping Date column\n",
    "df = df.drop(columns=['Dt_Customer'], axis=1)\n",
    "\n",
    "# Separating categorical and numerical columns\n",
    "cat_columns = df[['Education', 'Marital_Status', 'AcceptedCmp3', 'AcceptedCmp4',\n",
    "                  'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Response']]\n",
    "num_columns = df.drop(columns=cat_columns.columns)\n",
    "\n",
    "# Handling skewness and outliers\n",
    "df['Income'] = df['Income'].astype(int)\n",
    "skewed_features = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "                   'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
    "                   'NumWebPurchases', 'NumCatalogPurchases']\n",
    "\n",
    "for col in skewed_features:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "# Data preprocessing and feature engineering\n",
    "LE = LabelEncoder()\n",
    "df['Education'] = LE.fit_transform(df['Education'])\n",
    "df['Marital_Status'] = LE.fit_transform(df['Marital_Status'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(0.95)\n",
    "pca_data = pd.DataFrame(pca.fit_transform(df_scaled))\n",
    "\n",
    "# Clustering using KMeans\n",
    "WCSS = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(pca_data)\n",
    "    WCSS.append(kmeans.inertia_)\n",
    "\n",
    "# plt.plot(range(1, 11), WCSS, marker='o', linestyle='--')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.title('Elbow Method for Optimal k')\n",
    "# plt.show()\n",
    "\n",
    "# Silhouette Score method to find optimal k\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(pca_data)\n",
    "    silhouette_scores.append(silhouette_score(pca_data, labels))\n",
    "\n",
    "# plt.plot(range(2, 11), silhouette_scores, marker='o', linestyle='--')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('Silhouette Score')\n",
    "# plt.title('Silhouette Method for Optimal k')\n",
    "# plt.show()\n",
    "\n",
    "# Agglomerative Clustering\n",
    "linked = shc.linkage(pca_data, method='ward')\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# shc.dendrogram(linked)\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plt.xlabel('Samples')\n",
    "# plt.ylabel('Distance')\n",
    "# plt.show()\n",
    "\n",
    "agg_cluster = AgglomerativeClustering(n_clusters=3,  linkage='ward')\n",
    "labels = agg_cluster.fit_predict(pca_data)\n",
    "pca_data['Clusters'] = labels\n",
    "\n",
    "# Visualization of clusters\n",
    "\n",
    "\n",
    "#\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.scatterplot(x=pca_data.iloc[:, 0], y=pca_data.iloc[:, 1], hue=pca_data[\"Clusters\"], palette='viridis', marker='o')\n",
    "# plt.title('Agglomerative Clustering (PCA-reduced data)')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Profiling and analysis of clustering\n",
    "data_cleaned = df.copy()\n",
    "data_cleaned['Clusters'] = labels\n",
    "\n",
    "# Various visualizations and analysis\n",
    "# (Code for visualizations and analysis can be added here)\n",
    "\n",
    "# Classification for future clustering\n",
    "classif_data = data_cleaned[['Education', 'Marital_Status', 'Income', 'MntWines', 'MntFruits',\n",
    "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
    "       'AcceptedCmp2', 'Age', 'total_children', 'Clusters']]\n",
    "\n",
    "classif_data['Education'] = LE.fit_transform(classif_data['Education'])\n",
    "classif_data['Marital_Status'] = LE.fit_transform(classif_data['Marital_Status'])\n",
    "classif_scaled = pd.DataFrame(scaler.fit_transform(classif_data), columns=classif_data.columns)\n",
    "\n",
    "X = classif_data.drop('Clusters', axis=1)\n",
    "y = classif_data['Clusters']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Classification models\n",
    "from sklearn.metrics import  accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=11, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(\"GBM Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Additional code for analysis and visualizations can be added based on your requirements\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train your model (assuming 'gbm' is your trained model)\n",
    "# Save the model\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(gbm, model_file)\n",
    "\n",
    "# Assuming you have fitted scalers and encoders\n",
    "scaler = StandardScaler().fit(X_train)  # fit with your training data\n",
    "le_education = LabelEncoder().fit(X['Education'])\n",
    "le_marital_status = LabelEncoder().fit(X['Marital_Status'])\n",
    "\n",
    "# Save the scalers and encoders\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "with open('le_education.pkl', 'wb') as le_education_file:\n",
    "    pickle.dump(le_education, le_education_file)\n",
    "\n",
    "with open('le_marital_status.pkl', 'wb') as le_marital_status_file:\n",
    "    pickle.dump(le_marital_status, le_marital_status_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NB9Igrr8mK_b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB9Igrr8mK_b",
    "outputId": "bdd71175-b541-46f0-98c8-6768469f44e6"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom CSS for background image\n",
    "css = \"\"\"\n",
    "<style>\n",
    "body {\n",
    "    background-image: url('download.jfif');\n",
    "    background-size: cover;\n",
    "    background-attachment: fixed;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Inject the CSS into the Streamlit app\n",
    "st.markdown(css, unsafe_allow_html=True)\n",
    "\n",
    "# Load model, scaler, and encoders\n",
    "with open('model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "with open('le_education.pkl', 'rb') as le_education_file:\n",
    "    le_education = pickle.load(le_education_file)\n",
    "\n",
    "with open('le_marital_status.pkl', 'rb') as le_marital_status_file:\n",
    "    le_marital_status = pickle.load(le_marital_status_file)\n",
    "\n",
    "# Define mapping for dropdown options\n",
    "education_mapping = {0: 'Undergraduate', 1: 'Graduate', 2: 'Postgraduate'}\n",
    "marital_status_mapping = {0: 'Single', 1: 'Married'}\n",
    "\n",
    "# Reverse mapping for label encoding\n",
    "reverse_education_mapping = {v: k for k, v in education_mapping.items()}\n",
    "reverse_marital_status_mapping = {v: k for k, v in marital_status_mapping.items()}\n",
    "\n",
    "# Cluster information (replace with actual descriptions and recommendations)\n",
    "cluster_info = {\n",
    "    0: {\n",
    "        \"description\": \"Cluster 0: Customers have higher income and education levels, are generally married with moderate children, and prefer premium products like wines and gold.\",\n",
    "        \"recommendation\": \" Focus on premium offerings, implement exclusive loyalty programs, and enhance customer service to retain their high spending and engagement levels.\"\n",
    "    },\n",
    "    1: {\n",
    "        \"description\": \"Cluster 1: Customer group comprises married customers with moderate income and education, having more children and preferring affordable products like fruits and sweets.\",\n",
    "        \"recommendation\": \"Utilize value-oriented pricing, tailor family-oriented marketing, and leverage promotional strategies to appeal to their budget-conscious nature.\"\n",
    "    },\n",
    "    2: {\n",
    "        \"description\": \"Cluster 2: Comprises of younger customers with lower income and education levels, fewer children, and a preference for basic necessities and low-cost products.\",\n",
    "        \"recommendation\": \"Emphasize affordability, improve digital engagement with exclusive online promotions, and streamline purchasing processes for convenience.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Customer Clustering Prediction\")\n",
    "\n",
    "# Form to collect user inputs\n",
    "with st.form(\"prediction_form\"):\n",
    "    Education = st.selectbox(\"Education:\", options=list(education_mapping.values()))\n",
    "    Marital_Status = st.selectbox(\"Marital Status:\", options=list(marital_status_mapping.values()))\n",
    "    Income = st.number_input(\"Income:\", min_value=0)\n",
    "    MntWines = st.number_input(\"MntWines:\", min_value=0)\n",
    "    MntFruits = st.number_input(\"MntFruits:\", min_value=0)\n",
    "    MntMeatProducts = st.number_input(\"MntMeatProducts:\", min_value=0)\n",
    "    MntFishProducts = st.number_input(\"MntFishProducts:\", min_value=0)\n",
    "    MntSweetProducts = st.number_input(\"MntSweetProducts:\", min_value=0)\n",
    "    MntGoldProds = st.number_input(\"MntGoldProds:\", min_value=0)\n",
    "    NumDealsPurchases = st.number_input(\"NumDealsPurchases:\", min_value=0)\n",
    "    NumWebPurchases = st.number_input(\"NumWebPurchases:\", min_value=0)\n",
    "    NumCatalogPurchases = st.number_input(\"NumCatalogPurchases:\", min_value=0)\n",
    "    NumStorePurchases = st.number_input(\"NumStorePurchases:\", min_value=0)\n",
    "    NumWebVisitsMonth = st.number_input(\"NumWebVisitsMonth:\", min_value=0)\n",
    "    AcceptedCmp3 = st.number_input(\"AcceptedCmp3:\", min_value=0, max_value=1)\n",
    "    AcceptedCmp4 = st.number_input(\"AcceptedCmp4:\", min_value=0, max_value=1)\n",
    "    AcceptedCmp5 = st.number_input(\"AcceptedCmp5:\", min_value=0, max_value=1)\n",
    "    AcceptedCmp1 = st.number_input(\"AcceptedCmp1:\", min_value=0, max_value=1)\n",
    "    AcceptedCmp2 = st.number_input(\"AcceptedCmp2:\", min_value=0, max_value=1)\n",
    "    Age = st.number_input(\"Age:\", min_value=0)\n",
    "    TotalChildren = st.number_input(\"TotalChildren:\", min_value=0)\n",
    "\n",
    "    submitted = st.form_submit_button(\"Predict\")\n",
    "\n",
    "# Prediction logic\n",
    "if submitted:\n",
    "    # Prepare the input data\n",
    "    input_data = [\n",
    "        reverse_education_mapping[Education],\n",
    "        reverse_marital_status_mapping[Marital_Status],\n",
    "        Income, MntWines, MntFruits, MntMeatProducts, MntFishProducts,\n",
    "        MntSweetProducts, MntGoldProds, NumDealsPurchases, NumWebPurchases,\n",
    "        NumCatalogPurchases, NumStorePurchases, NumWebVisitsMonth,\n",
    "        AcceptedCmp3, AcceptedCmp4, AcceptedCmp5, AcceptedCmp1, AcceptedCmp2,\n",
    "        Age, TotalChildren\n",
    "    ]\n",
    "\n",
    "    # Scaling the numerical features\n",
    "    scaled_data = scaler.transform([input_data])\n",
    "\n",
    "    # Making prediction\n",
    "    prediction = model.predict(scaled_data)\n",
    "    predicted_cluster = prediction[0]\n",
    "\n",
    "    # Display the result\n",
    "    st.write(f\"The predicted customer cluster is: **{predicted_cluster}**\")\n",
    "    st.write(f\"Description: {cluster_info[predicted_cluster]['description']}\")\n",
    "    st.write(f\"Strategic Recommendation: {cluster_info[predicted_cluster]['recommendation']}\")\n",
    "\n",
    "    # Visualize input data for the predicted cluster\n",
    "    st.write(\"## Visualizations for the Predicted Cluster\")\n",
    "\n",
    "    if predicted_cluster == 0:\n",
    "        # Visualization 1: Spending distribution\n",
    "        labels = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "        spending = [MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds]\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.pie(spending, labels=labels, autopct='%1.1f%%')\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "        ax1.set_title(\"Spending Distribution for Cluster 0\")\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "        # Visualization 2: Income vs Spending\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        spending_data = [MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts + MntGoldProds]\n",
    "        sns.barplot(x=['Total Spending'], y=spending_data, ax=ax2)\n",
    "        ax2.set_title(\"Income vs Total Spending for Cluster 0\")\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "        # Visualization 3: Age Distribution\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        sns.histplot([Age], bins=10, kde=True, ax=ax3)\n",
    "        ax3.set_title(\"Age Distribution for Cluster 0\")\n",
    "        st.pyplot(fig3)\n",
    "\n",
    "    elif predicted_cluster == 1:\n",
    "        # Visualization 1: Spending distribution\n",
    "        labels = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "        spending = [MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds]\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.pie(spending, labels=labels, autopct='%1.1f%%')\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "        ax1.set_title(\"Spending Distribution for Cluster 1\")\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "        # Visualization 2: Purchase behavior\n",
    "        purchase_labels = ['Deals Purchases', 'Web Purchases', 'Catalog Purchases', 'Store Purchases']\n",
    "        purchase_counts = [NumDealsPurchases, NumWebPurchases, NumCatalogPurchases, NumStorePurchases]\n",
    "\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        sns.barplot(x=purchase_labels, y=purchase_counts, ax=ax2)\n",
    "        ax2.set_ylabel('Number of Purchases')\n",
    "        ax2.set_title(\"Purchase Behavior for Cluster 1\")\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "        # Visualization 3: Age Distribution\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        sns.histplot([Age], bins=10, kde=True, ax=ax3)\n",
    "        ax3.set_title(\"Age Distribution for Cluster 1\")\n",
    "        st.pyplot(fig3)\n",
    "\n",
    "    elif predicted_cluster == 2:\n",
    "        # Visualization 1: Spending distribution\n",
    "        labels = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "        spending = [MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds]\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.pie(spending, labels=labels, autopct='%1.1f%%')\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "        ax1.set_title(\"Spending Distribution for Cluster 2\")\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "        # Visualization 2: Web visits\n",
    "        st.write(\"Number of Web Visits per Month:\", NumWebVisitsMonth)\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        sns.barplot(x=['Web Visits'], y=[NumWebVisitsMonth], ax=ax2)\n",
    "        ax2.set_ylabel('Number of Web Visits')\n",
    "        ax2.set_title(\"Web Visits for Cluster 2\")\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "        # Visualization 3: Age Distribution\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        sns.histplot([Age], bins=10, kde=True, ax=ax3)\n",
    "        ax3.set_title(\"Age Distribution for Cluster 2\")\n",
    "        st.pyplot(fig3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TcuQJ3jWRo9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcuQJ3jWRo9g",
    "outputId": "d62f83be-d2bc-48d4-e7ed-ec89e6a56f2e"
   },
   "outputs": [],
   "source": [
    "! wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pNW-U3skQpgQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNW-U3skQpgQ",
    "outputId": "0a568208-cc23-4cdf-aea7-47e51fed2a17"
   },
   "outputs": [],
   "source": [
    "!streamlit run customer_segmentation.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_4mrBHoEyqbj",
   "metadata": {
    "id": "_4mrBHoEyqbj"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
